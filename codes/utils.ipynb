{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torch_geometric.data import Data, DataLoader, Dataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU, Embedding\n",
    "from torch_geometric.nn import GATConv, GCNConv, GINConv, TransformerConv\n",
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from prefetch_generator import BackgroundGenerator \n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def evaluate(label, predict, fold):\n",
    "    roc = roc_auc_score(label, predict)\n",
    "    pr = average_precision_score(label, predict)\n",
    "    return {'Fold':fold, 'ROC AUC':roc, 'PR AUC':pr}\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def global_select_concat(feature, batch, x):\n",
    "    feature = feature[x==-1]\n",
    "    batch_size = batch[-1].item() + 1\n",
    "    return feature.view(batch_size, -1)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class GCN_Model(torch.nn.Module):\n",
    "    def __init__(self, word_sizes, embed_dim,  n_output=2):\n",
    "        super(GCN_Model, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        #layers\n",
    "        self.embedding = Embedding(word_sizes, self.embed_dim)\n",
    "        self.gcn1 = GATConv(embed_dim, 50)\n",
    "        self.gcn2 = GATConv(50, 50)\n",
    "        self.gcn3 = GATConv(50, 100)\n",
    "        self.fc1 = Linear(200, 100)\n",
    "        self.output = nn.Linear(100, n_output)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # graph input feed-forward\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        feature = [torch.zeros(self.embed_dim).to(x.get_device()) if point==-1 else self.embedding(point) for point in x]\n",
    "        feature = self.gcn1(torch.stack(feature), edge_index)\n",
    "        feature = F.relu(feature)\n",
    "        feature = self.gcn2(feature, edge_index)\n",
    "        feature = F.relu(feature)\n",
    "        feature = self.gcn3(feature, edge_index)\n",
    "        feature = F.relu(feature)\n",
    "        feature = global_select_concat(feature, batch, x)\n",
    "        feature = self.fc1(feature)\n",
    "        feature = F.dropout(feature, 0.2)\n",
    "        out = self.output(feature)\n",
    "        return out\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, indexs, graph_map, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.root = root\n",
    "        self.indexs = indexs\n",
    "        self.graph_map = graph_map\n",
    "            \n",
    "    def len(self):\n",
    "        return len(self.indexs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        drug, pathway, label = self.graph_map[self.indexs[idx]]\n",
    "        with open('{}/graphs/{}+{}+{}.pkl'.format(self.root, drug, pathway, label), 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "        return data\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print('Start Time: {}'.format(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))))\n",
    "\n",
    "substructure_type = 'molecular graph'\n",
    "embed_dim = 11\n",
    "print('Type: ', substructure_type, 'Dim: ', embed_dim)\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "if not os.path.exists('model_tmp'):\n",
    "    os.mkdir('model_tmp')\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "with open('{}/graphs/graph_map.pkl'.format(substructure_type), 'rb') as file:\n",
    "    graph_map = pickle.load(file)\n",
    "with open('{}/entities2id.pkl'.format(substructure_type), 'rb') as file:\n",
    "    entities2id = pickle.load(file) \n",
    "with open('{}/train_test_val_indexs.pkl'.format(substructure_type), 'rb') as file:\n",
    "    train_test_val_indexs = pickle.load(file)\n",
    "    \n",
    "    \n",
    "results = []\n",
    "for fold, (train_indexs, test_indexs, val_indexs) in enumerate(train_test_val_indexs):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = GCN_Model(len(entities2id), embed_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    best_model_file = 'model_tmp/{}+{}+{}+GATConv.pt'.format(substructure_type, embed_dim, fold)\n",
    "    early_stopping = EarlyStopping(file=best_model_file, patience=5)\n",
    "    \n",
    "    train_dataset = MyOwnDataset(substructure_type, train_indexs, graph_map)\n",
    "    test_dataset = MyOwnDataset(substructure_type, test_indexs, graph_map)\n",
    "    val_dataset = MyOwnDataset(substructure_type, val_indexs, graph_map)\n",
    "    train_loader = BackgroundGenerator(DataLoader(train_dataset, batch_size=1000, shuffle=True))\n",
    "    test_loader = BackgroundGenerator(DataLoader(test_dataset, batch_size=1000))\n",
    "    val_loader = BackgroundGenerator(DataLoader(val_dataset, batch_size=1000))\n",
    "    if not os.path.exists(best_model_file):\n",
    "        model.train()\n",
    "        for epoch in range(1000):\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0\n",
    "            for data in train_loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(data)\n",
    "                loss = F.cross_entropy(logits, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                break\n",
    "\n",
    "            if epoch%10 == 0:\n",
    "                model.eval()\n",
    "                test_loss = 0\n",
    "                for data in test_loader:\n",
    "                    data = data.to(device)\n",
    "                    logits = model(data)\n",
    "                    test_loss = roc_auc_score(data.y.cpu().tolist(), logits.cpu()[:,1].tolist())\n",
    "                    break\n",
    "\n",
    "                print('{} Epoch {}: train loss {}, test ROC {}'.format(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())), epoch, train_loss, test_loss))\n",
    "                early_stopping(-test_loss, model)\n",
    "                if early_stopping.early_stop:\n",
    "                    print('Early Stopping')\n",
    "                    break\n",
    "\n",
    "    model = torch.load(best_model_file, map_location=device)\n",
    "    labels = []\n",
    "    predicts = []\n",
    "    for data in val_loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        labels.extend(data.y.cpu().tolist())\n",
    "        predicts.extend(F.softmax(logits, dim=1).cpu()[:,1].tolist())\n",
    "    result = evaluate(labels, predicts, fold)\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "results = pd.DataFrame(results)\n",
    "results['Type'] = substructure_type\n",
    "results['Dim'] = embed_dim\n",
    "results.to_csv('results/{}+{}+GATConv.csv'.format(substructure_type, embed_dim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(label, predict, fold):\n",
    "    roc = roc_auc_score(label, predict)\n",
    "    pr = average_precision_score(label, predict)\n",
    "    return {'Fold':fold, 'ROC AUC':roc, 'PR AUC':pr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, file='finish_model.pkl'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.file = file\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''\n",
    "        Saves model when validation loss decrease.\n",
    "        验证损失减少时保存模型。\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        # torch.save(model.state_dict(), 'checkpoint.pt')     # 这里会存储迄今最优模型的参数\n",
    "        torch.save(model, self.file)                 # 这里会存储迄今最优的模型\n",
    "        self.val_loss_min = val_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
